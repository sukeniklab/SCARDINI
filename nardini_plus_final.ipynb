{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unified IDP Analysis: Nardini+ features, CIDER parameters, and SPARROW parameters\n",
    "All in one environment, all in one output file\n",
    "Uses the proven Nardini calculation method with added CIDER and SPARROW features\n",
    "\n",
    "FEATURES INCLUDED:\n",
    "- Nardini: 54 features (raw + z-score) - compositional, physicochemical, patches\n",
    "- CIDER: 6 features - kappa, omega, delta, mean_net_charge, uversky_hydropathy, fraction_neutral\n",
    "- SPARROW: 7 features - SCD, SHD, complexity, fraction_proline,\n",
    "           scaled_rg, scaled_re, prefactor, scaling_exponent, asphericity\n",
    "\n",
    "Z-SCORE HANDLING:\n",
    "- Z-scores set to NaN when raw value is 0 (division by zero protection)\n",
    "- Z-scores set to NaN when reference std dev is near-zero\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from localcider.sequenceParameters import SequenceParameters as CIDER_SP\n",
    "from sparrow import Protein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SPARROW predictors...\n",
      "Predictors initialized.\n",
      "\n",
      "======================================================================\n",
      "Loading reference data for: Saccharomyces cerevisiae\n",
      "======================================================================\n",
      "Loaded 54 Nardini features.\n",
      "\n",
      "Loading FASTA file: test_seqs.fasta\n",
      "Loaded 4 sequences\n",
      "\n",
      "Calculating Nardini+ compositional features...\n",
      "Nardini+ features calculated.\n",
      "\n",
      "Calculating z-scores...\n",
      "Calculating CIDER and SPARROW parameters...\n",
      "CIDER and SPARROW calculation complete.\n",
      "\n",
      "Calculating SPARROW predictor features (DSSP, Mito, NES, NIS)...\n",
      "SPARROW predictor features calculated.\n",
      "\n",
      "======================================================================\n",
      "UNIFIED DATAFRAME SUMMARY\n",
      "======================================================================\n",
      "Total sequences: 4\n",
      "Total columns: 131\n",
      "  - Nardini raw: 54\n",
      "  - Nardini z-scores: 54\n",
      "  - CIDER: 6\n",
      "  - SPARROW basic: 9\n",
      "  - SPARROW predictors: 6\n",
      "======================================================================\n",
      "\n",
      "Saved to: test_idp_features.csv\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from localcider.sequenceParameters import SequenceParameters as CIDER_SP\n",
    "from sparrow import Protein\n",
    "import sparrow\n",
    "from parrot import brnn_architecture, encode_sequence\n",
    "from sparrow.sparrow_exceptions import SparrowException\n",
    "from sparrow.predictors.dssp.dssp_predictor import DSSPPredictor\n",
    "from sparrow.predictors.mitochondrial_targeting.mitochondrial_targeting_predictor import MitochondrialTargetingPredictor\n",
    "\n",
    "# ============================================================================\n",
    "# USER INPUTS\n",
    "# ============================================================================\n",
    "\n",
    "input_fasta_file = 'test_seqs.fasta'\n",
    "output_filename = 'test_idp_features'\n",
    "filetype = \"csv\"  # \"csv\" or \"excel\"\n",
    "\n",
    "calculate_zscores = True\n",
    "reference_species = \"Saccharomyces cerevisiae\"\n",
    "# Options: \"Homo sapiens\", \"Mus musculus\", \"Rattus norvegicus\", \"Xenopus tropicalis\",\n",
    "# \"Drosophila melanogaster\", \"Danio rerio\", \"Saccharomyces cerevisiae\",\n",
    "# \"Caenorhabditis elegans\", \"Arabidopsis thaliana\"\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTOR CLASSES (NLS and NES)\n",
    "# ============================================================================\n",
    "\n",
    "def softmax(v):\n",
    "    return (np.e ** v) / np.sum(np.e ** v)\n",
    "\n",
    "class NLSPredictor():\n",
    "    \"\"\"Predicts Nuclear Import Signals (NIS) - per-residue probability scores.\"\"\"\n",
    "    def __init__(self, version=\"1\"):\n",
    "        saved_weights = sparrow.get_data(f'networks/nuclear_import_signal/nls_predictor_network_v{version}.pt')\n",
    "        if not os.path.isfile(saved_weights):\n",
    "            raise SparrowException(f'Error: could not find weights file {saved_weights}')\n",
    "        \n",
    "        loaded_model = torch.load(saved_weights, map_location=torch.device('cpu'))\n",
    "        \n",
    "        num_layers = 0\n",
    "        while f'lstm.weight_ih_l{num_layers}' in loaded_model:\n",
    "            num_layers += 1\n",
    "        \n",
    "        self.number_of_classes = np.shape(loaded_model['fc.bias'])[0]\n",
    "        self.input_size = 20\n",
    "        self.hidden_vector_size = int(np.shape(loaded_model['lstm.weight_ih_l0'])[0] / 4)\n",
    "        self.number_of_layers = num_layers\n",
    "        \n",
    "        self.network = brnn_architecture.BRNN_MtM(\n",
    "            self.input_size, self.hidden_vector_size, num_layers, self.number_of_classes, 'cpu'\n",
    "        )\n",
    "        self.network.load_state_dict(loaded_model)\n",
    "\n",
    "    def predict_nuclear_import_signal(self, seq):\n",
    "        seq = seq.upper()\n",
    "        seq_vector = encode_sequence.one_hot(seq).view(1, len(seq), -1)\n",
    "        prediction = self.network(seq_vector.float()).detach().numpy().flatten()\n",
    "        prediction = prediction.reshape(-1, self.number_of_classes)\n",
    "        prediction = np.array(list(map(softmax, prediction)))\n",
    "        return [round(val[1], 5) for val in prediction]\n",
    "\n",
    "class NESPredictor():\n",
    "    \"\"\"Predicts Nuclear Export Signals (NES) - per-residue probability scores.\"\"\"\n",
    "    def __init__(self, version=\"1\"):\n",
    "        saved_weights = sparrow.get_data(f'networks/nuclear_export_signal/nes_predictor_network_v{version}.pt')\n",
    "        if not os.path.isfile(saved_weights):\n",
    "            raise SparrowException(f'Error: could not find weights file {saved_weights}')\n",
    "        \n",
    "        loaded_model = torch.load(saved_weights, map_location=torch.device('cpu'))\n",
    "        \n",
    "        num_layers = 0\n",
    "        while f'lstm.weight_ih_l{num_layers}' in loaded_model:\n",
    "            num_layers += 1\n",
    "        \n",
    "        self.number_of_classes = np.shape(loaded_model['fc.bias'])[0]\n",
    "        self.input_size = 20\n",
    "        self.hidden_vector_size = int(np.shape(loaded_model['lstm.weight_ih_l0'])[0] / 4)\n",
    "        self.number_of_layers = num_layers\n",
    "        \n",
    "        self.network = brnn_architecture.BRNN_MtM(\n",
    "            self.input_size, self.hidden_vector_size, num_layers, self.number_of_classes, 'cpu'\n",
    "        )\n",
    "        self.network.load_state_dict(loaded_model)\n",
    "\n",
    "    def predict_nes(self, seq):\n",
    "        seq = seq.upper()\n",
    "        seq_vector = encode_sequence.one_hot(seq).view(1, len(seq), -1)\n",
    "        prediction = self.network(seq_vector.float()).detach().numpy().flatten()\n",
    "        prediction = prediction.reshape(-1, self.number_of_classes)\n",
    "        prediction = np.array(list(map(softmax, prediction)))\n",
    "        return np.array([val[1] for val in prediction])\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALIZE SPARROW PREDICTORS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Initializing SPARROW predictors...\")\n",
    "dssp_predictor = DSSPPredictor()\n",
    "mito_predictor = MitochondrialTargetingPredictor()\n",
    "nes_predictor = NESPredictor()\n",
    "nls_predictor = NLSPredictor()\n",
    "print(\"Predictors initialized.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD REFERENCE DATA FOR Z-SCORES\n",
    "# ============================================================================\n",
    "\n",
    "if calculate_zscores:\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Loading reference data for: {reference_species}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sheetID = '1yxt0R1G0gdI2bGpjYXgk_h7-1qA6EY6J'\n",
    "    worksheetName = reference_species.split(\" \")[1]\n",
    "    currurl = f'https://docs.google.com/spreadsheets/d/{sheetID}/gviz/tq?tqx=out:csv&sheet={worksheetName}'\n",
    "    \n",
    "    speciesdf = pd.read_csv(currurl)\n",
    "    meanvals_species = speciesdf['Mean'].values\n",
    "    stdvals_species = speciesdf['Std'].values\n",
    "    mycompfeats_all = speciesdf['Feature'].tolist()\n",
    "    print(f\"Loaded {len(mycompfeats_all)} Nardini features.\\n\")\n",
    "else:\n",
    "    print(\"Z-score calculation disabled.\\n\")\n",
    "    aas = 'ACDEFGHIKLMNPQRSTVY'\n",
    "    mycompfeats_all = ['fracA', 'fracC', 'fracD', 'fracE', 'fracF', 'fracG', 'fracH', 'fracI',\n",
    "                        'fracK', 'fracL', 'fracM', 'fracN', 'fracP', 'fracQ', 'fracR', 'fracS',\n",
    "                        'fracT', 'fracV', 'fracW', 'fracY', 'fracpos', 'fracneg', 'fracpol',\n",
    "                        'fracali', 'fracaro', 'fracRtoK', 'fracEtoD', 'fracexp', 'fcr', 'ncpr',\n",
    "                        'mhydro', 'dispro', 'isopoi', 'ppii']\n",
    "    for aa in aas:\n",
    "        mycompfeats_all.append(f'patch{aa}')\n",
    "    mycompfeats_all.append('patchRG')\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD FASTA FILE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Loading FASTA file: {input_fasta_file}\")\n",
    "with open(input_fasta_file, 'r') as myfile:\n",
    "    Lines = myfile.readlines()\n",
    "\n",
    "subseqs, subnames = [], []\n",
    "thisseq = ''\n",
    "\n",
    "for line in Lines:\n",
    "    cleanline = line.strip()\n",
    "    if cleanline.startswith('>'):\n",
    "        subnames.append(cleanline[1:])\n",
    "        if thisseq:\n",
    "            subseqs.append(thisseq.upper())\n",
    "            thisseq = ''\n",
    "    else:\n",
    "        thisseq += cleanline\n",
    "subseqs.append(thisseq.upper())\n",
    "print(f\"Loaded {len(subseqs)} sequences\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE NARDINI+ COMPOSITIONAL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "numInt, minBlockLen = 2, 4\n",
    "aas = 'ACDEFGHIKLMNPQRSTVY'\n",
    "\n",
    "# Initialize all feature lists\n",
    "feat_lists = {name: [] for name in ['fracA','fracC','fracD','fracE','fracF','fracG','fracH','fracI',\n",
    "    'fracK','fracL','fracM','fracN','fracP','fracQ','fracR','fracS','fracT','fracV','fracW','fracY',\n",
    "    'fracpos','fracneg','fracpol','fracali','fracaro','fracRtoK','fracEtoD','fracexp','fcr','ncpr',\n",
    "    'mhydro','dispro','isopoi','ppii']}\n",
    "fracpatch = [[] for _ in range(len(aas))]\n",
    "rgpatch = []\n",
    "\n",
    "print(\"Calculating Nardini+ compositional features...\")\n",
    "\n",
    "for currseq in subseqs:\n",
    "    if len(currseq) >= 1 and not any(x in currseq for x in \"XUZJBO\"):\n",
    "        SeqOb = CIDER_SP(currseq)\n",
    "        slen = SeqOb.get_length()\n",
    "        aafrac = SeqOb.get_amino_acid_fractions()\n",
    "\n",
    "        feat_lists['fracexp'].append(SeqOb.get_fraction_expanding())\n",
    "        feat_lists['fcr'].append(SeqOb.get_FCR())\n",
    "        feat_lists['ncpr'].append(SeqOb.get_NCPR())\n",
    "        feat_lists['mhydro'].append(SeqOb.get_mean_hydropathy())\n",
    "        feat_lists['dispro'].append(SeqOb.get_fraction_disorder_promoting())\n",
    "        feat_lists['isopoi'].append(SeqOb.get_isoelectric_point())\n",
    "        feat_lists['ppii'].append(SeqOb.get_PPII_propensity(mode='hilser'))\n",
    "\n",
    "        for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "            feat_lists[f'frac{aa}'].append(aafrac[aa])\n",
    "\n",
    "        feat_lists['fracpos'].append(aafrac['K'] + aafrac['R'])\n",
    "        feat_lists['fracneg'].append(aafrac['D'] + aafrac['E'])\n",
    "        feat_lists['fracpol'].append(sum(aafrac[a] for a in 'QNSTGCH'))\n",
    "        feat_lists['fracali'].append(sum(aafrac[a] for a in 'ALMIV'))\n",
    "        feat_lists['fracaro'].append(sum(aafrac[a] for a in 'FWY'))\n",
    "        feat_lists['fracRtoK'].append(np.log10((slen*aafrac['R']+1)/(slen*aafrac['K']+1)))\n",
    "        feat_lists['fracEtoD'].append(np.log10((slen*aafrac['E']+1)/(slen*aafrac['D']+1)))\n",
    "\n",
    "        # Patches for each amino acid\n",
    "        for idx, aa in enumerate(aas):\n",
    "            pos = [i for i, ltr in enumerate(currseq) if ltr == aa]\n",
    "            pos2 = pos.copy()\n",
    "            for p in range(len(pos) - 1):\n",
    "                if 1 < pos[p+1] - pos[p] <= numInt + 1:\n",
    "                    pos2.extend(range(pos[p]+1, pos[p+1]))\n",
    "            \n",
    "            justKs = ['0'] * len(currseq)\n",
    "            for p in pos2:\n",
    "                justKs[p] = '1'\n",
    "            justKs = ''.join(justKs)\n",
    "            \n",
    "            patchescombined = ''\n",
    "            for m in re.finditer(r\"1+\", justKs):\n",
    "                subseq = currseq[m.start():m.end()]\n",
    "                if subseq.count(aa) >= minBlockLen:\n",
    "                    patchescombined += subseq\n",
    "            fracpatch[idx].append(len(patchescombined) / len(currseq))\n",
    "\n",
    "        # RG patch\n",
    "        pos = [i for i, ltr in enumerate(currseq) if ltr in 'RG']\n",
    "        pos2 = pos.copy()\n",
    "        for p in range(len(pos) - 1):\n",
    "            if 1 < pos[p+1] - pos[p] <= numInt + 1:\n",
    "                pos2.extend(range(pos[p]+1, pos[p+1]))\n",
    "        \n",
    "        justKs = ['0'] * len(currseq)\n",
    "        for p in pos2:\n",
    "            justKs[p] = '1'\n",
    "        justKs = ''.join(justKs)\n",
    "        \n",
    "        patchescombined = ''\n",
    "        for m in re.finditer(r\"1+\", justKs):\n",
    "            subseq = currseq[m.start():m.end()]\n",
    "            if subseq.count('RG') >= 2:\n",
    "                patchescombined += subseq\n",
    "        rgpatch.append(len(patchescombined) / len(currseq))\n",
    "    else:\n",
    "        for key in feat_lists:\n",
    "            feat_lists[key].append(np.nan)\n",
    "        for idx in range(len(aas)):\n",
    "            fracpatch[idx].append(np.nan)\n",
    "        rgpatch.append(np.nan)\n",
    "\n",
    "# Combine Nardini features\n",
    "compfeatvals_all = [feat_lists[f'frac{aa}'] for aa in 'ACDEFGHIKLMNPQRSTVWY']\n",
    "compfeatvals_all += [feat_lists[k] for k in ['fracpos','fracneg','fracpol','fracali','fracaro',\n",
    "    'fracRtoK','fracEtoD','fracexp','fcr','ncpr','mhydro','dispro','isopoi','ppii']]\n",
    "compfeatvals_all += fracpatch + [rgpatch]\n",
    "\n",
    "print(\"Nardini+ features calculated.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE NARDINI DATAFRAME\n",
    "# ============================================================================\n",
    "\n",
    "num_seqs, num_feats = len(subseqs), len(mycompfeats_all)\n",
    "subrawcomp = np.array([[compfeatvals_all[f][s] for f in range(num_feats)] for s in range(num_seqs)])\n",
    "raw_df = pd.DataFrame(data=subrawcomp, columns=mycompfeats_all)\n",
    "\n",
    "if calculate_zscores:\n",
    "    print(\"Calculating z-scores...\")\n",
    "    subzveccomp = np.zeros((num_seqs, num_feats))\n",
    "    min_std = 1e-10\n",
    "    \n",
    "    for s in range(num_seqs):\n",
    "        for f in range(num_feats):\n",
    "            raw_val = compfeatvals_all[f][s]\n",
    "            if raw_val == 0 or stdvals_species[f] < min_std:\n",
    "                subzveccomp[s, f] = np.nan\n",
    "            else:\n",
    "                subzveccomp[s, f] = (raw_val - meanvals_species[f]) / stdvals_species[f]\n",
    "    \n",
    "    raw_df.columns = [f\"nardini_{feat}_raw\" for feat in mycompfeats_all]\n",
    "    zscore_df = pd.DataFrame(subzveccomp, columns=[f\"nardini_{feat}_zscore\" for feat in mycompfeats_all])\n",
    "    nardini_df = pd.concat([raw_df, zscore_df], axis=1)\n",
    "else:\n",
    "    raw_df.columns = [f\"nardini_{feat}_raw\" for feat in mycompfeats_all]\n",
    "    nardini_df = raw_df\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE CIDER AND SPARROW PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Calculating CIDER and SPARROW parameters...\")\n",
    "cider_data, sparrow_data = [], []\n",
    "\n",
    "for idx, currseq in enumerate(subseqs):\n",
    "    if len(currseq) < 1 or any(x in currseq for x in \"XUZJBO\"):\n",
    "        cider_data.append({k: np.nan for k in ['cider_kappa','cider_omega','cider_delta',\n",
    "            'cider_uversky_hydropathy','cider_fraction_neutral','cider_length']})\n",
    "        sparrow_data.append({k: np.nan for k in ['sparrow_SCD','sparrow_SHD','sparrow_complexity',\n",
    "            'sparrow_fraction_proline','sparrow_scaled_rg','sparrow_scaled_re','sparrow_prefactor',\n",
    "            'sparrow_scaling_exponent','sparrow_asphericity']})\n",
    "        continue\n",
    "    \n",
    "    # CIDER\n",
    "    try:\n",
    "        SeqOb = CIDER_SP(currseq)\n",
    "        cider_data.append({\n",
    "            'cider_kappa': SeqOb.get_kappa(),\n",
    "            'cider_omega': SeqOb.get_Omega(),\n",
    "            'cider_delta': SeqOb.get_delta(),\n",
    "            'cider_uversky_hydropathy': SeqOb.get_uversky_hydropathy(),\n",
    "            'cider_fraction_neutral': SeqOb.get_countNeut() / SeqOb.get_length(),\n",
    "            'cider_length': SeqOb.get_length()\n",
    "        })\n",
    "    except:\n",
    "        cider_data.append({k: np.nan for k in ['cider_kappa','cider_omega','cider_delta',\n",
    "            'cider_uversky_hydropathy','cider_fraction_neutral','cider_length']})\n",
    "    \n",
    "    # SPARROW\n",
    "    try:\n",
    "        prot = Protein(currseq)\n",
    "        sparrow_dict = {'sparrow_SCD': prot.SCD, 'sparrow_SHD': prot.SHD,\n",
    "            'sparrow_complexity': prot.complexity, 'sparrow_fraction_proline': prot.fraction_proline}\n",
    "        for attr, method in [('sparrow_scaled_rg', lambda: prot.predictor.radius_of_gyration(use_scaled=True)),\n",
    "                             ('sparrow_scaled_re', lambda: prot.predictor.end_to_end_distance(use_scaled=True)),\n",
    "                             ('sparrow_prefactor', lambda: prot.predictor.prefactor()),\n",
    "                             ('sparrow_scaling_exponent', lambda: prot.predictor.scaling_exponent()),\n",
    "                             ('sparrow_asphericity', lambda: prot.predictor.asphericity())]:\n",
    "            try:\n",
    "                sparrow_dict[attr] = method()\n",
    "            except:\n",
    "                sparrow_dict[attr] = np.nan\n",
    "        sparrow_data.append(sparrow_dict)\n",
    "    except:\n",
    "        sparrow_data.append({k: np.nan for k in ['sparrow_SCD','sparrow_SHD','sparrow_complexity',\n",
    "            'sparrow_fraction_proline','sparrow_scaled_rg','sparrow_scaled_re','sparrow_prefactor',\n",
    "            'sparrow_scaling_exponent','sparrow_asphericity']})\n",
    "\n",
    "cider_df = pd.DataFrame(cider_data)\n",
    "sparrow_df = pd.DataFrame(sparrow_data)\n",
    "print(\"CIDER and SPARROW calculation complete.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE SPARROW PREDICTOR FEATURES (DSSP, Mito, NES, NIS)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Calculating SPARROW predictor features (DSSP, Mito, NES, NIS)...\")\n",
    "predictor_data = []\n",
    "\n",
    "for idx, currseq in enumerate(subseqs):\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f\"  Processing sequence {idx + 1}/{len(subseqs)}...\")\n",
    "    \n",
    "    if len(currseq) < 1 or any(x in currseq for x in \"XUZJBO\"):\n",
    "        predictor_data.append({\n",
    "            'sparrow_avg_helix_prob': np.nan,\n",
    "            'sparrow_avg_beta_prob': np.nan,\n",
    "            'sparrow_avg_coil_prob': np.nan,\n",
    "            'sparrow_avg_mito_targeting': np.nan,\n",
    "            'sparrow_avg_nes': np.nan,\n",
    "            'sparrow_avg_nis': np.nan\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    pred_dict = {}\n",
    "    \n",
    "    # DSSP secondary structure predictions\n",
    "    try:\n",
    "        dssp_probs = dssp_predictor.predict_dssp_probabilities(currseq)\n",
    "        pred_dict['sparrow_avg_helix_prob'] = dssp_probs[:, 0].mean()\n",
    "        pred_dict['sparrow_avg_beta_prob'] = dssp_probs[:, 1].mean()\n",
    "        pred_dict['sparrow_avg_coil_prob'] = dssp_probs[:, 2].mean()\n",
    "    except Exception as e:\n",
    "        if idx == 0:\n",
    "            print(f\"  Note: DSSP prediction failed: {e}\")\n",
    "        pred_dict['sparrow_avg_helix_prob'] = np.nan\n",
    "        pred_dict['sparrow_avg_beta_prob'] = np.nan\n",
    "        pred_dict['sparrow_avg_coil_prob'] = np.nan\n",
    "    \n",
    "    # Mitochondrial targeting\n",
    "    try:\n",
    "        mito_pred = np.array(mito_predictor.predict_mitochondrial_targeting(currseq))\n",
    "        pred_dict['sparrow_avg_mito_targeting'] = mito_pred.mean()\n",
    "    except Exception as e:\n",
    "        if idx == 0:\n",
    "            print(f\"  Note: Mito targeting prediction failed: {e}\")\n",
    "        pred_dict['sparrow_avg_mito_targeting'] = np.nan\n",
    "    \n",
    "    # Nuclear export signal (NES)\n",
    "    try:\n",
    "        nes_pred = nes_predictor.predict_nes(currseq)\n",
    "        pred_dict['sparrow_avg_nes'] = nes_pred.mean()\n",
    "    except Exception as e:\n",
    "        if idx == 0:\n",
    "            print(f\"  Note: NES prediction failed: {e}\")\n",
    "        pred_dict['sparrow_avg_nes'] = np.nan\n",
    "    \n",
    "    # Nuclear import signal (NIS/NLS)\n",
    "    try:\n",
    "        nis_pred = np.array(nls_predictor.predict_nuclear_import_signal(currseq))\n",
    "        pred_dict['sparrow_avg_nis'] = nis_pred.mean()\n",
    "    except Exception as e:\n",
    "        if idx == 0:\n",
    "            print(f\"  Note: NIS prediction failed: {e}\")\n",
    "        pred_dict['sparrow_avg_nis'] = np.nan\n",
    "    \n",
    "    predictor_data.append(pred_dict)\n",
    "\n",
    "predictor_df = pd.DataFrame(predictor_data)\n",
    "print(\"SPARROW predictor features calculated.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMBINE ALL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "name_df = pd.DataFrame({'Name': subnames})\n",
    "seq_df = pd.DataFrame({'Sequence': subseqs})\n",
    "\n",
    "final_df = pd.concat([name_df, seq_df, nardini_df, cider_df, sparrow_df, predictor_df], axis=1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"UNIFIED DATAFRAME SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total sequences: {len(final_df)}\")\n",
    "print(f\"Total columns: {len(final_df.columns)}\")\n",
    "print(f\"  - Nardini raw: {len([c for c in final_df.columns if 'nardini_' in c and '_raw' in c])}\")\n",
    "if calculate_zscores:\n",
    "    print(f\"  - Nardini z-scores: {len([c for c in final_df.columns if 'nardini_' in c and '_zscore' in c])}\")\n",
    "print(f\"  - CIDER: {len([c for c in final_df.columns if c.startswith('cider_')])}\")\n",
    "print(f\"  - SPARROW basic: {len([c for c in final_df.columns if c.startswith('sparrow_') and 'avg_' not in c])}\")\n",
    "print(f\"  - SPARROW predictors: {len([c for c in final_df.columns if 'sparrow_avg_' in c])}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE OUTPUT FILE\n",
    "# ============================================================================\n",
    "\n",
    "if filetype == 'csv':\n",
    "    output_file = f'{output_filename}.csv'\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "else:\n",
    "    output_file = f'{output_filename}.xlsx'\n",
    "    final_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f'Saved to: {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scardini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
